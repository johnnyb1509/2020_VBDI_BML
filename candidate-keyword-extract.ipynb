{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from underthesea import pos_tag, chunk, word_tokenize\n",
    "\n",
    "from nltk import RegexpParser, Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import underthesea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('text.txt', 'r', encoding=\"utf8\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vietnamese-stopwords.txt', 'r', encoding=\"utf8\") as f:\n",
    "    stopwords = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "NP = \"NP: {<N.*>? <V*> <N.*>? <A*>}\"\n",
    "chunker = RegexpParser(NP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_continuous_chunks(text, chunk_func=chunker.parse):\n",
    "    text_tokens = word_tokenize(text)\n",
    "    tokens_without_sw = [word for word in text_tokens if not word in stopwords]\n",
    "    filter_sent = (\" \").join(tokens_without_sw)\n",
    "    chunked = chunk_func(pos_tag(filter_sent))\n",
    "    continuous_chunk = []\n",
    "    current_chunk = []\n",
    "\n",
    "    for subtree in chunked:\n",
    "        if type(subtree) == Tree:\n",
    "            current_chunk.append(\" \".join([token for token, pos in subtree.leaves()]))\n",
    "        elif current_chunk:\n",
    "            named_entity = \" \".join(current_chunk)\n",
    "            if named_entity not in continuous_chunk:\n",
    "                continuous_chunk.append(named_entity)\n",
    "                current_chunk = []\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    return continuous_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sàn trúng thuận lợi',\n",
       " 'năm ngoái niêm yết muộn',\n",
       " 'sai hẹn ban đầu rõ ràng',\n",
       " 'BIDV đấu bình quân',\n",
       " 'thị trường diễn biến thuận lợi',\n",
       " 'NĐT định giá hợp lý',\n",
       " 'nắm bắt đầy đủ',\n",
       " 'Đặt kịch bản xấu',\n",
       " 'mua nhẹ nhàng',\n",
       " 'mắt cổ đông cổ đông thiệt thòi']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_continuous_chunks(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
